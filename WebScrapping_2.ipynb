{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d3571ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>RYSTAD ENERGY INDIA PRIVATE LIMITED</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst - Data Modeling/Quality</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Get My Parking</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst/Data Engineer</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mobile Premier League</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>Enquero</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Remote</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst - Immediate</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, C...</td>\n",
       "      <td>Perficient</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                       Data Analyst   \n",
       "1        Senior Data Analyst - Data Modeling/Quality   \n",
       "2                                Senior Data Analyst   \n",
       "3                        Data Analyst - CRM Platform   \n",
       "4                         Data Analyst/Data Engineer   \n",
       "5  Contractual Hiring For Top MNC || Business Dat...   \n",
       "6                                Senior Data Analyst   \n",
       "7                                Senior Data Analyst   \n",
       "8                                   Sr. Data Analyst   \n",
       "9                    Senior Data Analyst - Immediate   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "4  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7        Bangalore/Bengaluru, Hyderabad/Secunderabad   \n",
       "8                                             Remote   \n",
       "9  Bangalore/Bengaluru, Hyderabad/Secunderabad, C...   \n",
       "\n",
       "                          Company Name Experience Required  \n",
       "0  RYSTAD ENERGY INDIA PRIVATE LIMITED             0-3 Yrs  \n",
       "1                       Get My Parking             4-9 Yrs  \n",
       "2                              Walmart             4-7 Yrs  \n",
       "3                    Artech infosystem             1-6 Yrs  \n",
       "4                        Tech Mahindra             4-9 Yrs  \n",
       "5                            TeamLease             5-8 Yrs  \n",
       "6                Mobile Premier League             3-5 Yrs  \n",
       "7                              Enquero             3-8 Yrs  \n",
       "8                               McAfee             5-7 Yrs  \n",
       "9                           Perficient             5-7 Yrs  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 1\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#*** Entering Designation and Location\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')\n",
    "#***send key as bangalore for location\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')\n",
    "#***Submit the search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "#*** After Search wait for page to Load\n",
    "time.sleep(1)\n",
    "#*** Create Empty List for Job title, job location Company Name experience required\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#*** Scraping the job title and all details from given page using relative xpath\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "\n",
    "#*** Scrapping for the Location \n",
    "location_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#*** Scrapping for Company Name \n",
    "\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "\n",
    " #*** Scrap fpr Experience required\n",
    "experience_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tag[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)  \n",
    "\n",
    "# print the length of the list before creating a data frame\n",
    "driver.close() \n",
    "df=pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aedbb93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram</td>\n",
       "      <td>EXL</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hindustan Coca Cola Beverages (HCCB)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Manager II - Data science ( Marketplace)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>12-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>Bizongo</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                   Assistant Manager - Data Science   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "3                                     Data Scientist   \n",
       "4                             General Data Scientist   \n",
       "5    Senior Manager II - Data science ( Marketplace)   \n",
       "6                              Senior Data Scientist   \n",
       "7                                  Lead ML Scientist   \n",
       "8                                Data Scientist - II   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "3              Bangalore/Bengaluru, Gurgaon/Gurugram   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                        Bangalore/Bengaluru, Mumbai   \n",
       "8     Bangalore/Bengaluru, India, Mumbai (All Areas)   \n",
       "9                        Bangalore/Bengaluru, Mumbai   \n",
       "\n",
       "                                  Company Name Experience Required  \n",
       "0                                   CitiusTech             5-9 Yrs  \n",
       "1                                    Accenture             6-8 Yrs  \n",
       "2  NTT DATA Business Solutions Private Limited             4-9 Yrs  \n",
       "3                                          EXL             4-7 Yrs  \n",
       "4         Hindustan Coca Cola Beverages (HCCB)             3-8 Yrs  \n",
       "5                                      Walmart           12-15 Yrs  \n",
       "6                                      Walmart             5-9 Yrs  \n",
       "7                            Fractal Analytics            6-10 Yrs  \n",
       "8                                      Bizongo             3-6 Yrs  \n",
       "9                                 Baker Hughes             6-8 Yrs  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 2\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#*** Entering Designation and Location\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')\n",
    "#***send key as bangalore for location\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')\n",
    "#***Submit the search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "#*** After Search wait for page to Load\n",
    "time.sleep(1)\n",
    "#*** Create Empty List for Job title, job location Company Name experience required\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#*** Scraping the job title and all details from given page using relative xpath\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "\n",
    "#*** Scrapping for the Location \n",
    "location_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#*** Scrapping for Company Name \n",
    "\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "\n",
    " #*** Scrap fpr Experience required\n",
    "experience_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tag[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)  \n",
    "\n",
    "driver.close() \n",
    "\n",
    "df=pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02cb8dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search:::: <selenium.webdriver.remote.webelement.WebElement (session=\"db6abe738af62b1f05db5b3e44c83c59\", element=\"7e11c646-ac7b-4363-95e2-0f31c3024664\")>\n",
      "10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Alliance Recruitment Agency</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Avantive Solutions</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Title  \\\n",
       "0                       Data Scientist   \n",
       "1      DigitalBCG GAMMA Data Scientist   \n",
       "2                       Data Scientist   \n",
       "3  Data Scientist / Chat-bot Developer   \n",
       "4                  Lead Data Scientist   \n",
       "5                       Data Scientist   \n",
       "6                       Data Scientist   \n",
       "7                       Data Scientist   \n",
       "8                       Data Scientist   \n",
       "9             Knowledge/Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                 Noida, Nagpur, Bangalore/Bengaluru   \n",
       "1                     New Delhi, Bangalore/Bengaluru   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...   \n",
       "4         Noida(Sector-59 Noida)\\n(WFH during Covid)   \n",
       "5  Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                              Noida   \n",
       "8                                              Noida   \n",
       "9                                        Delhi / NCR   \n",
       "\n",
       "                  Company Name Experience Required  \n",
       "0                  GlobalLogic            8-10 Yrs  \n",
       "1      Boston Consulting Group             2-5 Yrs  \n",
       "2                        Optum             2-7 Yrs  \n",
       "3                 Big Seo Buzz             3-7 Yrs  \n",
       "4      R Systems International            7-10 Yrs  \n",
       "5         torcai digital media             2-7 Yrs  \n",
       "6               Feedback Infra             2-4 Yrs  \n",
       "7  Alliance Recruitment Agency             3-4 Yrs  \n",
       "8           Avantive Solutions            7-10 Yrs  \n",
       "9      BOLD Technology Systems             3-6 Yrs  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 3\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#*** Entering Designation and Location\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "#***Submit the search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "\n",
    "#*** After Search wait for page to Load\n",
    "time.sleep(5)\n",
    "\n",
    "#***Click Delhi / NCR for location filter\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]/label/p/span[1]\").click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Minimize filters Posted by, Industries, Top Companies, Education, Role Category, Company Type\n",
    "posted = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[10]/div/i\").click()\n",
    "industries = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[11]/div/i\").click()\n",
    "top_companies = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[12]/div/i\").click()\n",
    "education = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[9]/div/i\").click()\n",
    "role_cat = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[8]/div/i\").click()\n",
    "comp_type = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[7]/div/i\").click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Click 3-6 lakhs for salary\n",
    "salary = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]\").click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "#*** Create Empty List for Job title, job location Company Name experience required\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#*** Scraping the job title and all details from given page using relative xpath\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "\n",
    "#*** Scrapping for the Location \n",
    "location_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#*** Scrapping for Company Name \n",
    "\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "\n",
    " #*** Scrap fpr Experience required\n",
    "experience_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tag[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)  \n",
    "\n",
    "driver.close() \n",
    "df=pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3340f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "40\n",
      "80\n",
      "100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKYZA INDIA</td>\n",
       "      <td>Polarized, UV Protection Sports Sunglasses (Fr...</td>\n",
       "      <td>₹408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKYZA INDIA</td>\n",
       "      <td>Polarized, UV Protection Sports Sunglasses (Fr...</td>\n",
       "      <td>₹408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (65)</td>\n",
       "      <td>₹383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Mirrored, UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹5,029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Gradient Round Sunglasses (Free Size)</td>\n",
       "      <td>₹686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹1,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Retro Squar...</td>\n",
       "      <td>₹719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description   Price\n",
       "0      SKYZA INDIA  Polarized, UV Protection Sports Sunglasses (Fr...    ₹408\n",
       "1      SKYZA INDIA  Polarized, UV Protection Sports Sunglasses (Fr...    ₹408\n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹799\n",
       "3   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹319\n",
       "4           PIRASO           UV Protection Over-sized Sunglasses (65)    ₹383\n",
       "..             ...                                                ...     ...\n",
       "95   VINCENT CHASE    Mirrored, UV Protection Aviator Sunglasses (58)  ₹1,049\n",
       "96         Ray-Ban  by Lenskart Polarized, UV Protection Wayfarer ...  ₹5,029\n",
       "97   VINCENT CHASE              Gradient Round Sunglasses (Free Size)    ₹686\n",
       "98        Fastrack  Polarized, UV Protection Retro Square Sunglass...  ₹1,599\n",
       "99       ROYAL SON  UV Protection, Gradient Butterfly, Retro Squar...    ₹719\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 4\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "#*** Entering Designation and Location\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "Close_Login_Form=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\").click()\n",
    "\n",
    "#Search for Sunglasses\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search.send_keys('sunglasses')\n",
    "\n",
    "#***Submit the search button\n",
    "search_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\").click()\n",
    "\n",
    "#Wait for search to load\n",
    "time.sleep(5)\n",
    "\n",
    "#*** Create Empty List for Brand, Product Description and Price\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "\n",
    "def get_scrapped_data():\n",
    "    #*** Scraping the Brand\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    if(len(brand) < 80):\n",
    "        for i in brand_tag[0:len(brand_tag)]:\n",
    "            brand_text=i.text\n",
    "            brand.append(brand_text)\n",
    "    else:\n",
    "        for i in brand_tag[0:20]:\n",
    "            brand_text=i.text\n",
    "            brand.append(brand_text)\n",
    "\n",
    "\n",
    "    #*** Scrapping for the Product Description \n",
    "    pd_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    if(len(product_desc) < 80):\n",
    "        for i in pd_tag[0:len(pd_tag)]:\n",
    "            pd_text=i.text\n",
    "            product_desc.append(pd_text)\n",
    "    else:\n",
    "        for i in pd_tag[0:20]:\n",
    "            pd_text=i.text\n",
    "            product_desc.append(pd_text)\n",
    "    \n",
    "    #*** Scrapping for Price \n",
    "    price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    if(len(price) < 80):\n",
    "        for i in price_tag[0:len(price_tag)]:\n",
    "            price_text=i.text\n",
    "            price.append(price_text)\n",
    "    else:\n",
    "        for i in price_tag[0:20]:\n",
    "            price_text=i.text\n",
    "            price.append(price_text)\n",
    "\n",
    "while(len(brand)<100):\n",
    "    get_scrapped_data()\n",
    "    time.sleep(5)\n",
    "    if(len(brand) == 40):\n",
    "        driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\").click()\n",
    "    else:\n",
    "        if(len(brand) < 100):\n",
    "            driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\").click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "driver.close()\n",
    "df=pd.DataFrame({'Brand':brand,'Product Description':product_desc,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e3d1d4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "59\n",
      "69\n",
      "79\n",
      "88\n",
      "97\n",
      "100\n",
      "100 103 103\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It is better to buy iPhone 11 over iPhone 12 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>It was amazing experience for me. Honestly i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I bought iPhone 11 On March 2021, And I am Wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Just go for it.\\nThis phone is really amazing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       5   Highly recommended   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5            Excellent   \n",
       "97      5             Terrific   \n",
       "98      5            Excellent   \n",
       "99      5               Super!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  It is better to buy iPhone 11 over iPhone 12 i...  \n",
       "96  It was amazing experience for me. Honestly i a...  \n",
       "97  I bought iPhone 11 On March 2021, And I am Wri...  \n",
       "98  Just go for it.\\nThis phone is really amazing....  \n",
       "99  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 5\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "#*** Entering Designation and Location\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "Close_Login_Form=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\").click()\n",
    "\n",
    "#Search for Sunglasses\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search.send_keys('iphone 11')\n",
    "\n",
    "#***Submit the search button\n",
    "search_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\").click()\n",
    "\n",
    "#Wait for search to load\n",
    "time.sleep(5)\n",
    "\n",
    "#Click on Iphone 11 (Black 64 GB)\n",
    "iphoneLink = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[7]/div/div/div/a\").get_attribute(\"href\")\n",
    "\n",
    "driver.get(iphoneLink)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Click on All Reviews Link\n",
    "driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[6]/div/a\").click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#*** Create Empty List for Brand, Product Description and Price\n",
    "rating=[]\n",
    "review=[]\n",
    "full_review=[]\n",
    "\n",
    "def get_scrapped_data():\n",
    "    #*** Scraping the Brand\n",
    "    rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tag[0:len(rating_tag)]:\n",
    "        rating_text=i.text\n",
    "        rating.append(rating_text)\n",
    "\n",
    "\n",
    "    #*** Scrapping for the Product Description \n",
    "    review_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tag[0:len(review_tag)]:\n",
    "        review_text=i.text\n",
    "        review.append(review_text)\n",
    "    \n",
    "    #*** Scrapping for Price \n",
    "    full_review_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_review_tag[0:len(full_review_tag)]:\n",
    "        full_review_text=i.text\n",
    "        full_review.append(full_review_text)\n",
    "            \n",
    "    if(len(rating) == 10):\n",
    "        next_page = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]\").get_attribute(\"href\")\n",
    "        driver.get(next_page)\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        if(len(rating) < 100):\n",
    "            next_page = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\").get_attribute(\"href\")\n",
    "            driver.get(next_page)\n",
    "            time.sleep(5)\n",
    "\n",
    "while(len(rating)<100):\n",
    "    get_scrapped_data()\n",
    "    \n",
    "    \n",
    "    \n",
    "rating_100=[]\n",
    "review_100=[]\n",
    "full_review_100=[]\n",
    "\n",
    "for i in range(0,100):\n",
    "    rating_100.append(rating[i])\n",
    "    review_100.append(review[i])\n",
    "    full_review_100.append(full_review[i])\n",
    "    \n",
    "driver.close()\n",
    "df=pd.DataFrame({'Rating':rating_100,'Review Summary':review_100,'Full Review':full_review_100})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c8a8c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 111 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shoes Icon</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Premium Casual Shoes for Men Sneakers For Men</td>\n",
       "      <td>₹236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Zixer</td>\n",
       "      <td>Comfortable &amp; Ultra Light Weight Sneaker Sneak...</td>\n",
       "      <td>₹714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Xtoon</td>\n",
       "      <td>White Sneaker Sneakers For Men</td>\n",
       "      <td>₹424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>casual for men Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                                Product Description   Price\n",
       "0      Numenzo                                   Sneakers For Men    ₹559\n",
       "1   Shoes Icon      Modern Trendy Sneakers Shoes Sneakers For Men    ₹319\n",
       "2       BRUTON      Premium Casual Shoes for Men Sneakers For Men    ₹236\n",
       "3        BIRDE  Lightweight Pack Of 1 Trendy Sneakers Sneakers...    ₹299\n",
       "4       BRUTON                                   Sneakers For Men    ₹179\n",
       "..         ...                                                ...     ...\n",
       "95       Zixer  Comfortable & Ultra Light Weight Sneaker Sneak...    ₹714\n",
       "96   Deals4you                                   Sneakers For Men    ₹398\n",
       "97       Xtoon                     White Sneaker Sneakers For Men    ₹424\n",
       "98      DUCATI                                   Sneakers For Men  ₹1,289\n",
       "99      BRUTON                    casual for men Sneakers For Men    ₹499\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 6\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "#*** Entering Designation and Location\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "Close_Login_Form=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\").click()\n",
    "\n",
    "#Search for Sunglasses\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search.send_keys('sneakers')\n",
    "\n",
    "#***Submit the search button\n",
    "search_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\").click()\n",
    "\n",
    "#Wait for search to load\n",
    "time.sleep(5)\n",
    "\n",
    "#*** Create Empty List for Brand, Product Description and Price\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "\n",
    "def get_scrapped_data():\n",
    "    #*** Scraping the Brand\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    if(len(brand) < 80):\n",
    "        for i in brand_tag[0:len(brand_tag)]:\n",
    "            brand_text=i.text\n",
    "            brand.append(brand_text)\n",
    "    else:\n",
    "        for i in brand_tag[0:20]:\n",
    "            brand_text=i.text\n",
    "            brand.append(brand_text)\n",
    "\n",
    "\n",
    "    #*** Scrapping for the Product Description \n",
    "    pd_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    if(len(product_desc) < 80):\n",
    "        for i in pd_tag[0:len(pd_tag)]:\n",
    "            pd_text=i.text\n",
    "            product_desc.append(pd_text)\n",
    "    else:\n",
    "        for i in pd_tag[0:20]:\n",
    "            pd_text=i.text\n",
    "            product_desc.append(pd_text)\n",
    "    \n",
    "    #*** Scrapping for Price \n",
    "    price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    if(len(price) < 80):\n",
    "        for i in price_tag[0:len(price_tag)]:\n",
    "            price_text=i.text\n",
    "            price.append(price_text)\n",
    "    else:\n",
    "        for i in price_tag[0:20]:\n",
    "            price_text=i.text\n",
    "            price.append(price_text)\n",
    "\n",
    "while(len(brand)<100):\n",
    "    get_scrapped_data()\n",
    "    time.sleep(5)\n",
    "    if(len(brand) == 40):\n",
    "        driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\").click()\n",
    "    else:\n",
    "        if(len(brand) < 100):\n",
    "            driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\").click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "brand_100=[]\n",
    "product_desc_100=[]\n",
    "price_100=[]\n",
    "\n",
    "for i in range(0,100):\n",
    "    brand_100.append(brand[i])\n",
    "    product_desc_100.append(product_desc[i])\n",
    "    price_100.append(price[i])\n",
    "\n",
    "driver.close()\n",
    "df=pd.DataFrame({'Brand':brand_100,'Product Description':product_desc_100,'Price':price_100})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b6fd2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Shoe Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "      <td>Rs. 13995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Leather Niteball Sneakers</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Unisex Curry Basketball Shoes</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN LOW Basketball Shoe</td>\n",
       "      <td>Rs. 12795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Sports Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Running Sports Shoes</td>\n",
       "      <td>Rs. 10499Rs. 14999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Adizero Adios 7 Running</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Skateboarding Shoes</td>\n",
       "      <td>Rs. 8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Ozweego Sneakers</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                Shoe Description  \\\n",
       "0               Nike    Men React Infinity 3 Running   \n",
       "1   ADIDAS Originals   Men Leather Niteball Sneakers   \n",
       "2       UNDER ARMOUR   Unisex Curry Basketball Shoes   \n",
       "3               Nike  Men JORDAN LOW Basketball Shoe   \n",
       "4     Tommy Hilfiger              Men Solid Sneakers   \n",
       "..               ...                             ...   \n",
       "95          Skechers                Men Sports Shoes   \n",
       "96              Puma      Women Running Sports Shoes   \n",
       "97            ADIDAS     Men Adizero Adios 7 Running   \n",
       "98              Xtep         Men Skateboarding Shoes   \n",
       "99  ADIDAS Originals            Men Ozweego Sneakers   \n",
       "\n",
       "                          Price  \n",
       "0                     Rs. 13995  \n",
       "1                     Rs. 11999  \n",
       "2                     Rs. 10999  \n",
       "3                     Rs. 12795  \n",
       "4                      Rs. 7999  \n",
       "..                          ...  \n",
       "95                     Rs. 8999  \n",
       "96  Rs. 10499Rs. 14999(30% OFF)  \n",
       "97                    Rs. 11999  \n",
       "98                     Rs. 8599  \n",
       "99                    Rs. 10999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 7\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.myntra.com/shoes\")\n",
    "\n",
    "\n",
    "\n",
    "#*** After Search wait for page to Load\n",
    "time.sleep(5)\n",
    "\n",
    "#Click Black for color\n",
    "color = driver.find_element(By.XPATH, \"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\").click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#***Click Rs. 7179 to Rs. 14119 for Price filter\n",
    "price = driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\").click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "#*** Create Empty List for Job title, job location Company Name experience required\n",
    "brand=[]\n",
    "shoe_desc=[]\n",
    "shoe_price=[]\n",
    "\n",
    "\n",
    "def get_scrapped_data():\n",
    "    #*** Scraping the Brand\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in brand_tag[0:len(brand_tag)]:\n",
    "        brand_text=i.text\n",
    "        brand.append(brand_text)\n",
    "\n",
    "\n",
    "    #*** Scrapping for Shoe Description \n",
    "    shoe_desc_tag=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in shoe_desc_tag[0:len(shoe_desc_tag)]:\n",
    "        shoe_desc_text=i.text\n",
    "        shoe_desc.append(shoe_desc_text)\n",
    "\n",
    "    #*** Scrapping for Shoe Price \n",
    "    shoe_price_tag=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in shoe_price_tag[0:len(shoe_price_tag)]:\n",
    "        shoe_price_text=i.text\n",
    "        shoe_price.append(shoe_price_text)\n",
    "    \n",
    "    \n",
    "while(len(brand)<100):\n",
    "    get_scrapped_data()\n",
    "    time.sleep(5)\n",
    "    if(len(brand) == 50):\n",
    "        driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a\").click()\n",
    "    else:\n",
    "        if(len(brand) < 100):\n",
    "            driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[13]/a\").click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "\n",
    "driver.close() \n",
    "df=pd.DataFrame({'Brand':brand,'Shoe Description':shoe_desc,'Price':shoe_price})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b84de707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>61</td>\n",
       "      <td>80,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>8</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>44</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>25</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DELL Alienware x14 Gaming Laptop, Intel i7-127...</td>\n",
       "      <td>4</td>\n",
       "      <td>2,00,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td>1</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>78</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...</td>\n",
       "      <td>18</td>\n",
       "      <td>94,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...</td>\n",
       "      <td>89</td>\n",
       "      <td>1,06,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td>46</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....      61    80,900\n",
       "1  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...       8    82,990\n",
       "2  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...      44    57,990\n",
       "3  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...      25    82,990\n",
       "4  DELL Alienware x14 Gaming Laptop, Intel i7-127...       4  2,00,490\n",
       "5  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...       1    84,990\n",
       "6  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...      78    84,990\n",
       "7  Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...      18    94,990\n",
       "8  Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...      89  1,06,800\n",
       "9  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...      46    79,990"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 8\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "#*** Entering Designation and Location\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Search for Sunglasses\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search.send_keys('Laptop')\n",
    "\n",
    "#***Submit the search button\n",
    "search_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\").click()\n",
    "\n",
    "#Wait for search to load\n",
    "time.sleep(5)\n",
    "\n",
    "#Click on Intel Core i7 Filter\n",
    "coreI7 = driver.find_elements(By.XPATH,'//span[@class=\"a-list-item\"]')\n",
    "for i in coreI7[0:len(coreI7)]:\n",
    "    if(i.text == \"Intel Core i7\"):\n",
    "        i.click()\n",
    "        break;\n",
    "    else:\n",
    "        continue;\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "#*** Create Empty List for Title, Rating and Price\n",
    "rating=[]\n",
    "title=[]\n",
    "price=[]\n",
    "\n",
    "#*** Scraping the Title\n",
    "title_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title_text=i.text\n",
    "    title.append(title_text)\n",
    "\n",
    "\n",
    "#*** Scrapping for the Rating \n",
    "rating_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-size-base s-underline-text\"]')\n",
    "for i in rating_tag[0:10]:\n",
    "    rating_text=i.text\n",
    "    rating.append(rating_text)\n",
    "\n",
    "#*** Scrapping for Price \n",
    "price_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tag[0:10]:\n",
    "    price_text=i.text\n",
    "    price.append(price_text)\n",
    "\n",
    "driver.close()\n",
    "df=pd.DataFrame({'Title':title,'Ratings':rating,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11c56d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Posted On</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EY GDS</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLOBALLOGIC INDIA PRIVATE LIMITED</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EY</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company Name Posted On Rating\n",
       "0                   GENPACT India Private Limited    4d ago    4.0\n",
       "1  Optum Global Solutions (India) Private Limited   11d ago    4.1\n",
       "2  BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED    9d ago    4.3\n",
       "3                                          EY GDS   11d ago    3.8\n",
       "4               GLOBALLOGIC INDIA PRIVATE LIMITED    9d ago    4.0\n",
       "5                   GENPACT India Private Limited  1mon ago    4.0\n",
       "6                                         Genpact  1mon ago    4.0\n",
       "7        Ericsson India Global Services Pvt. Ltd.  1mon ago    4.3\n",
       "8                         Dew Solutions Pvt. Ltd.   16d ago    4.3\n",
       "9                                              EY  1mon ago    3.8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 9\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "#*** Entering Designation and Location\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close Ad\n",
    "Close_Ad=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[4]/div/div/button\").click()\n",
    "\n",
    "#Go to Jobs Page\n",
    "driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/header/nav/ul/li[5]/a\").click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Search for Data Scientist\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "search.send_keys('Data Scientist')\n",
    "\n",
    "#***Submit the search button\n",
    "search_btn=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button\").click()\n",
    "\n",
    "#Wait for search to load\n",
    "time.sleep(5)\n",
    "\n",
    "#Click on Location Filter\n",
    "driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]\").click()\n",
    "time.sleep(1)\n",
    "\n",
    "#Search Noida in search bar of location\n",
    "driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\").send_keys('Noida')\n",
    "time.sleep(1)\n",
    "\n",
    "#Click on Noida radio button\n",
    "driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\").click()\n",
    "time.sleep(5)\n",
    "\n",
    "#*** Create Empty List for Title, Rating and Price\n",
    "company_name=[]\n",
    "posted_ago=[]\n",
    "rating=[]\n",
    "\n",
    "#*** Scraping the Company Name\n",
    "name_tag=driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]')\n",
    "for i in name_tag[0:10]:\n",
    "    name=i.text\n",
    "    company_name.append(name)\n",
    "\n",
    "\n",
    "#*** Scrapping for the Posted Ago \n",
    "posted_tag=driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]')\n",
    "index=0\n",
    "for i in posted_tag[0:20]:\n",
    "    if(index%2 == 0):\n",
    "        posted=i.text\n",
    "        posted_ago.append(posted)\n",
    "    index+=1\n",
    "    \n",
    "#*** Scrapping for Price \n",
    "rating_tag=driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]')\n",
    "for i in rating_tag[0:10]:\n",
    "    rating_text=i.text\n",
    "    rating.append(rating_text)\n",
    "\n",
    "    \n",
    "driver.close()\n",
    "df=pd.DataFrame({'Company Name':company_name,'Posted On':posted_ago,'Rating':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60342ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total Salary Records</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>(based on 23 salaries)</td>\n",
       "      <td>₹ 32.3L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>(based on 57 salaries)</td>\n",
       "      <td>₹ 19.9L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>(based on 49 salaries)</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>(based on 34 salaries)</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>(based on 115 salaries)</td>\n",
       "      <td>₹ 15.4L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>(based on 68 salaries)</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sigmoid Analytics</td>\n",
       "      <td>(based on 10 salaries)</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>1 yr experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>(based on 11 salaries)</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>(based on 10 salaries)</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>(based on 14 salaries)</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>3 yrs experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company Name     Total Salary Records Average Salary  \\\n",
       "0                     Walmart   (based on 23 salaries)        ₹ 32.3L   \n",
       "1                    Ab Inbev   (based on 57 salaries)        ₹ 19.9L   \n",
       "2                       Optum   (based on 49 salaries)        ₹ 16.4L   \n",
       "3                          ZS   (based on 34 salaries)        ₹ 15.8L   \n",
       "4           Fractal Analytics  (based on 115 salaries)        ₹ 15.4L   \n",
       "5             Tiger Analytics   (based on 68 salaries)        ₹ 14.7L   \n",
       "6           Sigmoid Analytics   (based on 10 salaries)        ₹ 14.7L   \n",
       "7  Legato Health Technologies   (based on 11 salaries)        ₹ 14.5L   \n",
       "8                        HSBC   (based on 10 salaries)        ₹ 14.0L   \n",
       "9                    Tredence   (based on 14 salaries)        ₹ 13.9L   \n",
       "\n",
       "  Minimum Salary Maximum Salary Experience Required  \n",
       "0        ₹ 25.0L        ₹ 45.0L  3-4 yrs experience  \n",
       "1        ₹ 15.0L        ₹ 26.0L  2-4 yrs experience  \n",
       "2        ₹ 11.0L        ₹ 22.6L  2-4 yrs experience  \n",
       "3        ₹ 11.0L        ₹ 22.0L  1-2 yrs experience  \n",
       "4         ₹ 9.0L        ₹ 23.0L  2-4 yrs experience  \n",
       "5         ₹ 9.0L        ₹ 20.0L  2-4 yrs experience  \n",
       "6        ₹ 12.7L        ₹ 19.7L     1 yr experience  \n",
       "7        ₹ 11.0L        ₹ 20.0L    4 yrs experience  \n",
       "8        ₹ 12.0L        ₹ 18.0L    4 yrs experience  \n",
       "9         ₹ 8.8L        ₹ 17.5L    3 yrs experience  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Question 10\n",
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#Chrome Version 105.0.5195.127\n",
    "#downloaded the Chrome webdriver and extract all and \n",
    "\n",
    "#*** Connect to the Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\mrimc\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "# or driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#***Opening Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "#*** Entering Designation and Location\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close Ad\n",
    "Close_Ad=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[4]/div/div/button\").click()\n",
    "\n",
    "#Hover on Salaries Link and Click on Browse salaries\n",
    "driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/header/nav/ul/li[3]\").click()\n",
    "time.sleep(1)\n",
    "driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/a\").click();\n",
    "time.sleep(5)\n",
    "\n",
    "#Send Data Scientist element\n",
    "driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\").send_keys(\"Data Scientist\")\n",
    "time.sleep(1)\n",
    "#select data scientist option from autocomplete\n",
    "driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p\").click()\n",
    "time.sleep(5)\n",
    "\n",
    "comp_name=[]\n",
    "tot_sal_record=[]\n",
    "avg_sal=[]\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "exp_req=[]\n",
    "\n",
    "\n",
    "#Scrap company name\n",
    "name_tag = driver.find_elements(By.XPATH,\"//a[@data-v-4c07f399]\")\n",
    "for i in name_tag[0:10]:\n",
    "    name=i.text.split('\\n')\n",
    "    comp_name.append(name[0])\n",
    "    \n",
    "#Scrap total Salary records\n",
    "tot_sal_tag = driver.find_elements(By.XPATH,'//span[@class=\"datapoints\"]')\n",
    "for i in tot_sal_tag[0:10]:\n",
    "    tot_sal=i.text\n",
    "    tot_sal_record.append(tot_sal)\n",
    "    \n",
    "#Scrap average salary\n",
    "avg_tag = driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in avg_tag[0:10]:\n",
    "    avg=i.text\n",
    "    avg_sal.append(avg)\n",
    "\n",
    "#Scrap min max salary\n",
    "min_max_tag = driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "index=0\n",
    "for i in min_max_tag[0:20]:\n",
    "    if(index%2==0):\n",
    "        min_s = i.text\n",
    "        min_sal.append(min_s)\n",
    "    else:\n",
    "        max_s=i.text\n",
    "        max_sal.append(max_s)\n",
    "    index+=1\n",
    "        \n",
    "#Scrap experience required\n",
    "exp_req_tag = driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]')\n",
    "for i in exp_req_tag[0:10]:\n",
    "    exp=i.text.split(\" (\")\n",
    "    exp_req.append(exp[0])\n",
    "        \n",
    "driver.close()\n",
    "df=pd.DataFrame({'Company Name':comp_name,'Total Salary Records':tot_sal_record,'Average Salary':avg_sal, 'Minimum Salary':min_sal, 'Maximum Salary':max_sal, 'Experience Required':exp_req})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4876c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
